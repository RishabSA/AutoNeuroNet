{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c30f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"build\")\n",
    "import _autoneuronet as ann\n",
    "\n",
    "# import autoneuronet as ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5db84",
   "metadata": {},
   "source": [
    "# MNIST Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e21f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\"./data\", train=True, download=True)\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False)\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf207b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_dataset.data.numpy()\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_images = test_images.reshape(test_images.shape[0], -1)\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f461f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(train_images[0].reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(f\"Label: {train_labels[0]}\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_matrix(array: any, *, as_column: bool = False) -> ann.Matrix:\n",
    "    \"\"\"Convert a numpy array or sequence to a Matrix.\"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    numpy_array = np.asarray(array, dtype=float)\n",
    "    if numpy_array.ndim == 0:\n",
    "        numpy_array = numpy_array.reshape(1, 1)\n",
    "    elif numpy_array.ndim == 1:\n",
    "        numpy_array = (\n",
    "            numpy_array.reshape((-1, 1)) if as_column else numpy_array.reshape((1, -1))\n",
    "        )\n",
    "    elif numpy_array.ndim != 2:\n",
    "        raise ValueError(\"Expected a 1D or 2D array\")\n",
    "\n",
    "    rows, cols = numpy_array.shape\n",
    "    matrix = ann.Matrix(int(rows), int(cols))\n",
    "    for i in range(rows):\n",
    "        matrix[i] = numpy_array[i].tolist()\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54cdb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(numpy_array: np.ndarray, batch_size: int = 16):\n",
    "    num_samples = numpy_array.shape[0]\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        yield numpy_array[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61c9d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_matrices = []\n",
    "train_labels_matrices = []\n",
    "\n",
    "test_images_matrices = []\n",
    "test_labels_matrices = []\n",
    "\n",
    "for batch in batch_generator(train_images, batch_size):\n",
    "    batch_matrix = numpy_to_matrix(batch)\n",
    "    train_images_matrices.append(batch_matrix)\n",
    "\n",
    "for batch in batch_generator(train_labels, batch_size):\n",
    "    batch_matrix = numpy_to_matrix(batch)\n",
    "    train_labels_matrices.append(batch_matrix)\n",
    "\n",
    "for batch in batch_generator(test_images, batch_size):\n",
    "    batch_matrix = numpy_to_matrix(batch)\n",
    "    test_images_matrices.append(batch_matrix)\n",
    "\n",
    "for batch in batch_generator(test_labels, batch_size):\n",
    "    batch_matrix = numpy_to_matrix(batch)\n",
    "    test_labels_matrices.append(batch_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54adb114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork =\n",
       "Linear(784, 128)\n",
       "ReLU()\n",
       "Linear(128, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "model = ann.NeuralNetwork(\n",
    "    [\n",
    "        ann.Linear(784, 128, init=\"he\"),\n",
    "        ann.ReLU(),\n",
    "        ann.Linear(128, 10, init=\"he\"),\n",
    "        # ann.Softmax(),\n",
    "    ]\n",
    ")\n",
    "optimizer = ann.SGDOptimizer(\n",
    "    learning_rate=lr, model=model, momentum=momentum, weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66298204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 1: 100%|██████████| 3750/3750 [30:36<00:00,  2.04it/s, loss=0.01167406]\n",
      "Training the MNIST Neural Network:   7%|▋         | 1/15 [30:36<7:08:27, 1836.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.24758720103009366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 2: 100%|██████████| 3750/3750 [29:03<00:00,  2.15it/s, loss=0.00601283]\n",
      "Training the MNIST Neural Network:  13%|█▎        | 2/15 [59:39<6:25:59, 1781.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss: 0.11448748878427129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 3: 100%|██████████| 3750/3750 [31:03<00:00,  2.01it/s, loss=0.00505896]\n",
      "Training the MNIST Neural Network:  20%|██        | 3/15 [1:30:42<6:03:46, 1818.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss: 0.0822210579487786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 4: 100%|██████████| 3750/3750 [37:16<00:00,  1.68it/s, loss=0.00383831]\n",
      "Training the MNIST Neural Network:  27%|██▋       | 4/15 [2:07:59<6:03:41, 1983.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss: 0.06313852159819358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 5: 100%|██████████| 3750/3750 [31:10<00:00,  2.00it/s, loss=0.00400545]\n",
      "Training the MNIST Neural Network:  33%|███▎      | 5/15 [2:39:10<5:23:50, 1943.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss: 0.05054140903126979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 6: 100%|██████████| 3750/3750 [31:02<00:00,  2.01it/s, loss=0.00314466]\n",
      "Training the MNIST Neural Network:  40%|████      | 6/15 [3:10:12<4:47:19, 1915.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss: 0.0409247077815438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 7: 100%|██████████| 3750/3750 [30:35<00:00,  2.04it/s, loss=0.00280769]\n",
      "Training the MNIST Neural Network:  47%|████▋     | 7/15 [3:40:47<4:11:54, 1889.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss: 0.03378042129214475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 8: 100%|██████████| 3750/3750 [30:28<00:00,  2.05it/s, loss=0.00246036]\n",
      "Training the MNIST Neural Network:  53%|█████▎    | 8/15 [4:11:16<3:38:10, 1870.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss: 0.0282121594544419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 9: 100%|██████████| 3750/3750 [30:31<00:00,  2.05it/s, loss=0.00225823]\n",
      "Training the MNIST Neural Network:  60%|██████    | 9/15 [4:41:48<3:05:48, 1858.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss: 0.023781547032366658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 10: 100%|██████████| 3750/3750 [30:30<00:00,  2.05it/s, loss=0.00198596]\n",
      "Training the MNIST Neural Network:  67%|██████▋   | 10/15 [5:12:19<2:34:08, 1849.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss: 0.020243771656658943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 11: 100%|██████████| 3750/3750 [30:36<00:00,  2.04it/s, loss=0.00182898]\n",
      "Training the MNIST Neural Network:  73%|███████▎  | 11/15 [5:42:55<2:03:02, 1845.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss: 0.017539408936651752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 12: 100%|██████████| 3750/3750 [30:47<00:00,  2.03it/s, loss=0.00180618]\n",
      "Training the MNIST Neural Network:  80%|████████  | 12/15 [6:13:43<1:32:18, 1846.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss: 0.015452639380010381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 13: 100%|██████████| 3750/3750 [30:54<00:00,  2.02it/s, loss=0.00166261]\n",
      "Training the MNIST Neural Network:  87%|████████▋ | 13/15 [6:44:38<1:01:37, 1848.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss: 0.013885466166200818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 14: 100%|██████████| 3750/3750 [30:53<00:00,  2.02it/s, loss=0.00152740]\n",
      "Training the MNIST Neural Network:  93%|█████████▎| 14/15 [7:15:32<30:50, 1850.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss: 0.012590432237508263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MNIST Neural Network 15: 100%|██████████| 3750/3750 [30:57<00:00,  2.02it/s, loss=0.00157528]\n",
      "Training the MNIST Neural Network: 100%|██████████| 15/15 [7:46:30<00:00, 1866.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss: 0.011569604350680584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Epoch: 15 | Train Loss: 0.011569604350680584\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training the MNIST Neural Network\"):\n",
    "    train_loss = 0.0\n",
    "    num_train_batches = 0\n",
    "\n",
    "    training_pbar = tqdm(\n",
    "        zip(train_images_matrices, train_labels_matrices),\n",
    "        total=min(\n",
    "            len(train_images_matrices),\n",
    "            len(train_labels_matrices),\n",
    "        ),\n",
    "        desc=f\"Training MNIST Neural Network {epoch + 1}\",\n",
    "    )\n",
    "\n",
    "    for batched_images_matrix, batched_labels_matrix in training_pbar:\n",
    "        optimizer.resetGrad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model.forward(batched_images_matrix)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = ann.CrossEntropyLossWithLogits(batched_labels_matrix, y_pred)\n",
    "\n",
    "        loss_val = loss.getVal()\n",
    "        train_loss += loss_val\n",
    "\n",
    "        training_pbar.set_postfix(\n",
    "            loss=f\"{loss_val:.8f}\",\n",
    "        )\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.setGrad(1.0)\n",
    "        loss.backward()\n",
    "        optimizer.optimize()\n",
    "\n",
    "        num_train_batches += 1\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} | Train Loss: {train_loss / num_train_batches}\")\n",
    "\n",
    "    os.makedirs(\"models/mnist\", exist_ok=True)\n",
    "    model.saveWeights(f\"models/mnist/mnist_model_epoch_{epoch + 1}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecbaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing MNIST Neural Network 15: 100%|██████████| 625/625 [04:16<00:00,  2.43it/s, acc=97.80%, loss=0.00012911]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.07210141299932878\n",
      "Test Accuracy: 97.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Loop\n",
    "# Test Loss: 0.07210141299932878\n",
    "# Test Accuracy: 97.80%\n",
    "\n",
    "test_loss_sum = 0.0\n",
    "num_test_batches = 0\n",
    "\n",
    "test_acc_correct = 0\n",
    "test_acc_total = 0\n",
    "\n",
    "testing_pbar = tqdm(\n",
    "    zip(test_images_matrices, test_labels_matrices),\n",
    "    total=min(\n",
    "        len(test_images_matrices),\n",
    "        len(test_labels_matrices),\n",
    "    ),\n",
    "    desc=f\"Testing MNIST Neural Network\",\n",
    ")\n",
    "\n",
    "for batched_images_matrix, batched_labels_matrix in testing_pbar:\n",
    "    # Forward pass\n",
    "    y_pred = model.forward(batched_images_matrix)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = ann.CrossEntropyLossWithLogits(batched_labels_matrix, y_pred)\n",
    "\n",
    "    test_loss_val = loss.getVal()\n",
    "    test_loss_sum += test_loss_val\n",
    "\n",
    "    for i in range(y_pred.rows):\n",
    "        best_pred = 0\n",
    "        best_val = y_pred[i, 0].getVal()\n",
    "        for j in range(1, y_pred.cols):\n",
    "            val = y_pred[i, j].getVal()\n",
    "\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best_pred = j\n",
    "\n",
    "        label = int(batched_labels_matrix[i, 0].getVal())\n",
    "        if best_pred == label:\n",
    "            test_acc_correct += 1\n",
    "\n",
    "        test_acc_total += 1\n",
    "\n",
    "    testing_pbar.set_postfix(\n",
    "        loss=f\"{test_loss_val:.8f}\",\n",
    "        acc=f\"{(test_acc_correct / test_acc_total) * 100:.2f}%\",\n",
    "    )\n",
    "\n",
    "    num_test_batches += 1\n",
    "\n",
    "print(f\"Test Loss: {test_loss_sum / num_test_batches}\")\n",
    "print(f\"Test Accuracy: {(test_acc_correct / test_acc_total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "677d022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: ann.NeuralNetwork, image: np.ndarray, label: int):\n",
    "    image_matrix = numpy_to_matrix(image.reshape(1, -1))\n",
    "    logits = model.forward(image_matrix)\n",
    "\n",
    "    logits_numpy = np.array([logits[0, i].getVal() for i in range(logits.cols)])\n",
    "    exps = np.exp(logits_numpy - logits_numpy.max())\n",
    "    probs = exps / exps.sum()\n",
    "\n",
    "    pred = int(np.argmax(probs))\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(image.reshape(28, 28), cmap=\"gray\")\n",
    "    title = f\"True Label: {label} | Pred Label: {pred}\"\n",
    "    plt.title(title)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "    return pred, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de1e6503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs:\n",
      "0: 0.0000%\n",
      "1: 0.0000%\n",
      "2: 0.0000%\n",
      "3: 0.0084%\n",
      "4: 0.0000%\n",
      "5: 0.0000%\n",
      "6: 0.0000%\n",
      "7: 99.9911%\n",
      "8: 0.0000%\n",
      "9: 0.0005%\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "pred, probs = predict(model, test_images[idx], test_labels[idx])\n",
    "\n",
    "print(\"Probs:\")\n",
    "for i, prob in enumerate(probs):\n",
    "    print(f\"{i}: {prob * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14e6825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loadWeights(\"models/mnist/mnist_model_epoch_15.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa52d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
