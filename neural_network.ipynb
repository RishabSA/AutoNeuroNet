{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from build.autodiff import Var, Matrix, NeuralNetwork, computeMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc3f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "N = 10\n",
    "\n",
    "X = Matrix(N, in_dim)  # shape: (N, 1)\n",
    "Y_labels = Matrix(N, out_dim)  # shape: (N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbf77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training data\n",
    "for i in range(N):\n",
    "    X[i, 0] = Var(i)\n",
    "    Y_labels[i, 0] = 5.0 * i + 3.0\n",
    "    # y = 5x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c55b828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork =\n",
       "[1 -> 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "epochs = 1000\n",
    "\n",
    "model = NeuralNetwork([(in_dim, out_dim)])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6203c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 855.9965644644811\n",
      "Epoch: 101 | Train Loss: 0.4305055875552699\n",
      "Epoch: 201 | Train Loss: 0.13869874231943552\n",
      "Epoch: 301 | Train Loss: 0.04468546211034522\n",
      "Epoch: 401 | Train Loss: 0.014396601516518037\n",
      "Epoch: 501 | Train Loss: 0.004638245313735261\n",
      "Epoch: 601 | Train Loss: 0.0014943331984082317\n",
      "Epoch: 701 | Train Loss: 0.0004814388970010374\n",
      "Epoch: 801 | Train Loss: 0.00015510825282638482\n",
      "Epoch: 901 | Train Loss: 4.997221920523793e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Reset gradients and the old graph\n",
    "    X.resetGradAndParents()\n",
    "    Y_labels.resetGradAndParents()\n",
    "\n",
    "    for layer in model.layers:\n",
    "        W, b = layer\n",
    "\n",
    "        W.resetGradAndParents()\n",
    "        b.resetGradAndParents()\n",
    "\n",
    "    # Forward pass\n",
    "    Y_pred = model.forward(X)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = computeMSELoss(Y_labels, Y_pred)\n",
    "    loss_val = loss.getVal()\n",
    "\n",
    "    # Backpropagation (Reverse-Mode Automatic Differentiation)\n",
    "    loss.setGrad(1.0)\n",
    "    loss.backward()\n",
    "\n",
    "    # Backpropagation and Gradient Descent for each parameter\n",
    "    for layer in model.layers:\n",
    "        W, b = layer\n",
    "\n",
    "        # Update W\n",
    "        for i in range(W.rows):\n",
    "            for j in range(W.cols):\n",
    "                weight_param = W[i, j]\n",
    "\n",
    "                # Partial derivative of the Loss function with respect to the weight parameter\n",
    "                gradient = weight_param.getGrad()\n",
    "                weight_param.setVal(weight_param.getVal() - lr * gradient)\n",
    "\n",
    "        # Update b\n",
    "        for i in range(b.rows):\n",
    "            for j in range(b.cols):\n",
    "                bias_param = b[i, j]\n",
    "\n",
    "                # Partial derivative of the Loss function with respect to the bias parameter\n",
    "                gradient = bias_param.getGrad()\n",
    "                bias_param.setVal(bias_param.getVal() - lr * gradient)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | Train Loss: {loss_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8379f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Labels:\n",
      "Matrix(10 x 1) = \n",
      "3.000000 \n",
      "8.000000 \n",
      "13.000000 \n",
      "18.000000 \n",
      "23.000000 \n",
      "28.000000 \n",
      "33.000000 \n",
      "38.000000 \n",
      "43.000000 \n",
      "48.000000 \n",
      "\n",
      "\n",
      "Final Model Predictions:\n",
      "Matrix(10 x 1) = \n",
      "2.992543 \n",
      "7.993732 \n",
      "12.994922 \n",
      "17.996111 \n",
      "22.997300 \n",
      "27.998489 \n",
      "32.999678 \n",
      "38.000867 \n",
      "43.002057 \n",
      "48.003246 \n",
      "\n",
      "Learned W(0, 0) = Var(val=5.001189, grad=0.000675)\n",
      "Learned b(0, 0) = Var(val=2.992543, grad=-0.004235)\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "Y_pred_final = model.forward(X)\n",
    "\n",
    "print(f\"Ground Truth Labels:\\n{Y_labels}\\n\")\n",
    "print(f\"Final Model Predictions:\\n{Y_pred_final}\")\n",
    "\n",
    "first_layer = model.layers[0]\n",
    "W_learned, b_learned = first_layer\n",
    "\n",
    "print(f\"Learned W(0, 0) = {W_learned[0, 0]}\")\n",
    "print(f\"Learned b(0, 0) = {b_learned[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_blobs\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "y = y * 2 - 1  # make y be -1 or 1\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap=\"jet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
